{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script to merge census tracts and the isochrones generated from those tracts. It combines each isochrone and tract into a single polygon using their unique GEOID, then finds the number of grocery stores within each tract, and finally merges the store count data with the original tract shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import cenpy as cp\n",
    "import numpy as np\n",
    "import os\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_int_cols(df, col1, col2, col3, fill1=2, fill2=3, fill3=6, return_col='GEOID'):\n",
    "    \"\"\" Concatenate integer columns using zfill \"\"\"\n",
    "    df[[col1, col2, col3]] = df[[col1, col2, col3]].astype(str)\n",
    "    df[col1] = df[col1].str.zfill(fill1)\n",
    "    df[col2] = df[col2].str.zfill(fill2)\n",
    "    df[col3] = df[col3].str.zfill(fill3)\n",
    "    df[return_col] = df[[col1, col2, col3]].apply(lambda x: ''.join(x), axis=1)\n",
    "    df[[col1, col2, col3, return_col]] = df[[col1, col2, col3, return_col]].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all shapefiles for merging isochrones and tracts\n",
    "tracts = gpd.read_file(os.path.join('shapefiles', 'ti_2017_chi_tracts_simple.shp'))\n",
    "isos = gpd.read_file(os.path.join('shapefiles', 'isochrones.shp'))\n",
    "tracts = tracts[['GEOID', 'geometry']]\n",
    "isos = isos[['GEOID', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate tracts and isochones\n",
    "gdf = gpd.GeoDataFrame(pd.concat([tracts, isos], ignore_index=True))\n",
    "gdf.index = gdf['GEOID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the isochrone and tract polygons\n",
    "fix = []\n",
    "GEOID_list = gdf['GEOID'].unique()\n",
    "for i, id in enumerate(GEOID_list):\n",
    "    tmp = gdf[gdf['GEOID']==id].geometry\n",
    "    sh = MultiPolygon([x.buffer(0) for x in tmp.geometry])\n",
    "    fix.append({'GEOID': id, 'geometry':sh})\n",
    "merged = gpd.GeoDataFrame(fix, columns=['GEOID', 'geometry'])\n",
    "merged = merged.set_geometry('geometry')\n",
    "merged['geometry'] = merged.geometry.buffer(0)\n",
    "merged.crs = tracts.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shapefile of points from the lat, long of grocery store queries\n",
    "df = pd.read_csv(os.path.join('data', 'all_markets.csv'))\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df.longitude, df.latitude)]\n",
    "points = gpd.GeoDataFrame(df, crs=merged.crs, geometry=geometry)\n",
    "points.to_file(os.path.join('shapefiles', 'final_chi_points.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       POP  STATEFIP  COUNTY   TRACT        GEOID\n",
      "0     4558        17       1     100  17001000100\n",
      "1     1900        17       1     201  17001000201\n",
      "2     2666        17       1     202  17001000202\n",
      "3     3399        17       1     400  17001000400\n",
      "4     2415        17       1     500  17001000500\n",
      "5     3759        17       1     600  17001000600\n",
      "6     1243        17       1     700  17001000700\n",
      "7     2929        17       1     800  17001000800\n",
      "8     2603        17       1     900  17001000900\n",
      "9     3737        17       1    1001  17001001001\n",
      "10    3645        17       1    1002  17001001002\n",
      "11    8076        17       1    1100  17001001100\n",
      "12    4333        17       1   10100  17001010100\n",
      "13    3524        17       1   10200  17001010200\n",
      "14    6083        17       1   10300  17001010300\n",
      "15    3219        17       1   10400  17001010400\n",
      "16    3040        17       1   10500  17001010500\n",
      "17    5952        17       1   10600  17001010600\n",
      "18    2392        17       3  957600  17003957600\n",
      "19    1893        17       3  957700  17003957700\n",
      "20    1733        17       3  957800  17003957800\n",
      "21    1346        17       3  957900  17003957900\n",
      "22    2868        17       5  951200  17005951200\n",
      "23    6790        17       5  951300  17005951300\n",
      "24    3179        17       5  951400  17005951400\n",
      "25    4476        17       5  951500  17005951500\n",
      "26    8308        17       7   10100  17007010100\n",
      "27    5898        17       7   10200  17007010200\n",
      "28    6648        17       7   10300  17007010300\n",
      "29    7076        17       7   10400  17007010400\n",
      "...    ...       ...     ...     ...          ...\n",
      "3093  3888        17     201    3707  17201003707\n",
      "3094  2830        17     201    3708  17201003708\n",
      "3095  1706        17     201    3709  17201003709\n",
      "3096  2458        17     201    3710  17201003710\n",
      "3097  4763        17     201    3711  17201003711\n",
      "3098  6258        17     201    3801  17201003801\n",
      "3099  7114        17     201    3805  17201003805\n",
      "3100  4814        17     201    3806  17201003806\n",
      "3101  7694        17     201    3807  17201003807\n",
      "3102  3821        17     201    3808  17201003808\n",
      "3103  4804        17     201    3809  17201003809\n",
      "3104  4682        17     201    3901  17201003901\n",
      "3105  5983        17     201    3903  17201003903\n",
      "3106  4664        17     201    3904  17201003904\n",
      "3107  8858        17     201    4001  17201004001\n",
      "3108  6926        17     201    4002  17201004002\n",
      "3109  2096        17     201    4003  17201004003\n",
      "3110  5077        17     201    4100  17201004100\n",
      "3111  6370        17     201    4200  17201004200\n",
      "3112  5099        17     201    4300  17201004300\n",
      "3113     0        17     201  980000  17201980000\n",
      "3114  2570        17     203   30100  17203030100\n",
      "3115  2961        17     203   30200  17203030200\n",
      "3116  2990        17     203   30300  17203030300\n",
      "3117  5717        17     203   30400  17203030400\n",
      "3118  7779        17     203   30501  17203030501\n",
      "3119  2638        17     203   30502  17203030502\n",
      "3120  6508        17     203   30601  17203030601\n",
      "3121  3360        17     203   30602  17203030602\n",
      "3122  4583        17     203   30700  17203030700\n",
      "\n",
      "[3123 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/jupyterenv/lib/python3.6/site-packages/cenpy/remote.py:172: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  df[cols] = df[cols].convert_objects(convert_numeric=convert_numeric)\n"
     ]
    }
   ],
   "source": [
    "# Query census API to get tract level population\n",
    "api_conn = cp.base.Connection('ACSSF5Y2015')\n",
    "pop = api_conn.query(['B01001_001E'], geo_unit='tract:*', geo_filter = {'state':'17'})\n",
    "pop.rename(\n",
    "    columns={\n",
    "        'B01001_001E': 'POP',\n",
    "        'state': 'STATEFIP',\n",
    "        'county': 'COUNTY',\n",
    "        'tract': 'TRACT'\n",
    "        },\n",
    "        inplace=True)\n",
    "pop = concat_int_cols(pop, 'STATEFIP', 'COUNTY', 'TRACT')\n",
    "pop['GEOID'] = pop['GEOID'].astype(str)\n",
    "print(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the grocery store points with the merged tracts to determine counts, output final shapefile\n",
    "counts = gpd.sjoin(merged, points, how='left', op='contains')\n",
    "counts = pd.DataFrame(counts)\n",
    "counts = counts.groupby('GEOID').size().reset_index(name='counts')\n",
    "counts['GEOID'] = counts['GEOID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CRS does not match!\n"
     ]
    }
   ],
   "source": [
    "# Merge neighborhood information onto each census tracts\n",
    "tracts = gpd.read_file(os.path.join('shapefiles', 'ti_2017_chi_tracts_simple.shp'))\n",
    "neighborhoods = gpd.read_file(os.path.join('shapefiles', 'ti_2012_chi_neighborhoods.shp')).to_crs(epsg = 4269)\n",
    "tandh = gpd.sjoin(\n",
    "    tracts.set_geometry(tracts.centroid),\n",
    "    neighborhoods,\n",
    "    how='left',\n",
    "    op='within')\n",
    "tandh = pd.DataFrame(tandh[['GEOID', 'PRI_NEIGH']])\n",
    "tandh['GEOID'] = tandh['GEOID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the files together, calculate the stores per 1K population, then output to shapefile\n",
    "tracts = gpd.read_file(os.path.join('shapefiles', 'ti_2017_chi_tracts_simple.shp'))\n",
    "tracts = tracts\\\n",
    "  .merge(counts, on='GEOID')\\\n",
    "  .merge(pop, on='GEOID')\\\n",
    "  .merge(tandh, on='GEOID')\n",
    "tracts['STORES_PER_1000'] = tracts['counts'] / tracts['POP'] * 1000\n",
    "tracts = tracts.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "tracts = gpd.GeoDataFrame(tracts)\n",
    "tracts.to_file(os.path.join('shapefiles', 'final_chi_tracts.shp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyterenv]",
   "language": "python",
   "name": "conda-env-jupyterenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
