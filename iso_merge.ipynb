{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script to merge census tracts and the isochrones generated from those tracts. It combines each isochrone and tract into a single polygon using their unique GEOID, then finds the number of grocery stores within each tract, and finally merges the store count data with the original tract shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import cenpy as cp\n",
    "import numpy as np\n",
    "import os\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_int_cols(df, col1, col2, col3, fill1=2, fill2=3, fill3=6, return_col='GEOID'):\n",
    "    \"\"\" Concatenate integer columns using zfill \"\"\"\n",
    "    df[[col1, col2, col3]] = df[[col1, col2, col3]].astype(str)\n",
    "    df[col1] = df[col1].str.zfill(fill1)\n",
    "    df[col2] = df[col2].str.zfill(fill2)\n",
    "    df[col3] = df[col3].str.zfill(fill3)\n",
    "    df[return_col] = df[[col1, col2, col3]].apply(lambda x: ''.join(x), axis=1)\n",
    "    df[[col1, col2, col3, return_col]] = df[[col1, col2, col3, return_col]].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all shapefiles for merging isochrones and tracts\n",
    "tracts = gpd.read_file(os.path.join('shapefiles', 'ti_2017_chi_tracts_simple.shp'))\n",
    "isos = gpd.read_file(os.path.join('shapefiles', 'isochrones.shp'))\n",
    "tracts = tracts[['GEOID', 'geometry']]\n",
    "isos = isos[['GEOID', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate tracts and isochones\n",
    "gdf = gpd.GeoDataFrame(pd.concat([tracts, isos], ignore_index=True))\n",
    "gdf.index = gdf['GEOID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the isochrone and tract polygons\n",
    "fix = []\n",
    "GEOID_list = gdf['GEOID'].unique()\n",
    "for i, id in enumerate(GEOID_list):\n",
    "    tmp = gdf[gdf['GEOID']==id].geometry\n",
    "    sh = MultiPolygon([x.buffer(0) for x in tmp.geometry])\n",
    "    fix.append({'GEOID': id, 'geometry':sh})\n",
    "merged = gpd.GeoDataFrame(fix, columns=['GEOID', 'geometry'])\n",
    "merged = merged.set_geometry('geometry')\n",
    "merged['geometry'] = merged.geometry.buffer(0)\n",
    "merged.crs = tracts.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shapefile of points from the lat, long of grocery store queries\n",
    "df = pd.read_csv(os.path.join('data', 'all_markets.csv'))\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df.longitude, df.latitude)]\n",
    "df = df.drop(['longitude', 'latitude'], axis=1)\n",
    "points = gpd.GeoDataFrame(df, crs=merged.crs, geometry=geometry)\n",
    "points.to_file(os.path.join('shapefiles', 'final_chi_points.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       POP  STATEFIP  COUNTY   TRACT        GEOID\n",
      "0     4558        17       1     100  17001000100\n",
      "1     1900        17       1     201  17001000201\n",
      "2     2666        17       1     202  17001000202\n",
      "3     3399        17       1     400  17001000400\n",
      "4     2415        17       1     500  17001000500\n",
      "5     3759        17       1     600  17001000600\n",
      "6     1243        17       1     700  17001000700\n",
      "7     2929        17       1     800  17001000800\n",
      "8     2603        17       1     900  17001000900\n",
      "9     3737        17       1    1001  17001001001\n",
      "10    3645        17       1    1002  17001001002\n",
      "11    8076        17       1    1100  17001001100\n",
      "12    4333        17       1   10100  17001010100\n",
      "13    3524        17       1   10200  17001010200\n",
      "14    6083        17       1   10300  17001010300\n",
      "15    3219        17       1   10400  17001010400\n",
      "16    3040        17       1   10500  17001010500\n",
      "17    5952        17       1   10600  17001010600\n",
      "18    2392        17       3  957600  17003957600\n",
      "19    1893        17       3  957700  17003957700\n",
      "20    1733        17       3  957800  17003957800\n",
      "21    1346        17       3  957900  17003957900\n",
      "22    2868        17       5  951200  17005951200\n",
      "23    6790        17       5  951300  17005951300\n",
      "24    3179        17       5  951400  17005951400\n",
      "25    4476        17       5  951500  17005951500\n",
      "26    8308        17       7   10100  17007010100\n",
      "27    5898        17       7   10200  17007010200\n",
      "28    6648        17       7   10300  17007010300\n",
      "29    7076        17       7   10400  17007010400\n",
      "...    ...       ...     ...     ...          ...\n",
      "3093  3888        17     201    3707  17201003707\n",
      "3094  2830        17     201    3708  17201003708\n",
      "3095  1706        17     201    3709  17201003709\n",
      "3096  2458        17     201    3710  17201003710\n",
      "3097  4763        17     201    3711  17201003711\n",
      "3098  6258        17     201    3801  17201003801\n",
      "3099  7114        17     201    3805  17201003805\n",
      "3100  4814        17     201    3806  17201003806\n",
      "3101  7694        17     201    3807  17201003807\n",
      "3102  3821        17     201    3808  17201003808\n",
      "3103  4804        17     201    3809  17201003809\n",
      "3104  4682        17     201    3901  17201003901\n",
      "3105  5983        17     201    3903  17201003903\n",
      "3106  4664        17     201    3904  17201003904\n",
      "3107  8858        17     201    4001  17201004001\n",
      "3108  6926        17     201    4002  17201004002\n",
      "3109  2096        17     201    4003  17201004003\n",
      "3110  5077        17     201    4100  17201004100\n",
      "3111  6370        17     201    4200  17201004200\n",
      "3112  5099        17     201    4300  17201004300\n",
      "3113     0        17     201  980000  17201980000\n",
      "3114  2570        17     203   30100  17203030100\n",
      "3115  2961        17     203   30200  17203030200\n",
      "3116  2990        17     203   30300  17203030300\n",
      "3117  5717        17     203   30400  17203030400\n",
      "3118  7779        17     203   30501  17203030501\n",
      "3119  2638        17     203   30502  17203030502\n",
      "3120  6508        17     203   30601  17203030601\n",
      "3121  3360        17     203   30602  17203030602\n",
      "3122  4583        17     203   30700  17203030700\n",
      "\n",
      "[3123 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/jupyterenv/lib/python3.6/site-packages/cenpy/remote.py:172: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  df[cols] = df[cols].convert_objects(convert_numeric=convert_numeric)\n"
     ]
    }
   ],
   "source": [
    "# Query census API to get tract level population\n",
    "api_conn = cp.base.Connection('ACSSF5Y2015')\n",
    "pop = api_conn.query(['B01001_001E'], geo_unit='tract:*', geo_filter = {'state':'17'})\n",
    "pop.rename(\n",
    "    columns={\n",
    "        'B01001_001E': 'POP',\n",
    "        'state': 'STATEFIP',\n",
    "        'county': 'COUNTY',\n",
    "        'tract': 'TRACT'\n",
    "        },\n",
    "        inplace=True)\n",
    "pop = concat_int_cols(pop, 'STATEFIP', 'COUNTY', 'TRACT')\n",
    "pop['GEOID'] = pop['GEOID'].astype(str)\n",
    "print(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the grocery store points with the merged tracts to determine counts, output final shapefile\n",
    "counts = gpd.sjoin(merged, points, how='left', op='contains')\n",
    "counts = pd.DataFrame(counts)\n",
    "counts = counts.groupby('GEOID').size().reset_index(name='counts')\n",
    "counts['GEOID'] = counts['GEOID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CRS does not match!\n",
      "           GEOID           PRI_NEIGH\n",
      "0    17031842400             Chatham\n",
      "1    17031843700        North Center\n",
      "2    17031010502         Rogers Park\n",
      "3    17031020602          West Ridge\n",
      "4    17031030701           Edgewater\n",
      "5    17031031100              Uptown\n",
      "6    17031040300      Lincoln Square\n",
      "7    17031050800        North Center\n",
      "8    17031060400           Lake View\n",
      "9    17031062200           Lake View\n",
      "10   17031062900           Lake View\n",
      "11   17031070200        Lincoln Park\n",
      "12   17031070400  Sheffield & DePaul\n",
      "13   17031071100  Sheffield & DePaul\n",
      "14   17031081000         River North\n",
      "15   17031081401       Streeterville\n",
      "16   17031110100      Jefferson Park\n",
      "17   17031140500         Albany Park\n",
      "18   17031151001        Portage Park\n",
      "19   17031161000         Irving Park\n",
      "20   17031170700             Dunning\n",
      "21   17031190402      Belmont Cragin\n",
      "22   17031200200             Hermosa\n",
      "23   17031210700            Avondale\n",
      "24   17031221300        Logan Square\n",
      "25   17031230100       Humboldt Park\n",
      "26   17031240300         Wicker Park\n",
      "27   17031241200         Wicker Park\n",
      "28   17031241600           West Town\n",
      "29   17031242500   Ukrainian Village\n",
      "..           ...                 ...\n",
      "771  17031630500           Gage Park\n",
      "772  17031837300       Garfield Park\n",
      "773  17031832300            Bucktown\n",
      "774  17031836400             Oakland\n",
      "775  17031838000       United Center\n",
      "776  17031841500      North Lawndale\n",
      "777  17031650500           West Lawn\n",
      "778  17031700502             Ashburn\n",
      "779  17031720500             Beverly\n",
      "780  17031740200     Mount Greenwood\n",
      "781  17031070600        Lincoln Park\n",
      "782  17031150300        Portage Park\n",
      "783  17031611100            New City\n",
      "784  17031730500  Washington Heights\n",
      "785  17031171000             Dunning\n",
      "786  17031220500        Logan Square\n",
      "787  17031240900       Humboldt Park\n",
      "788  17031242000           West Town\n",
      "789  17031243500           West Town\n",
      "790  17031271400       Garfield Park\n",
      "791  17031292500      North Lawndale\n",
      "792  17031030104           Edgewater\n",
      "793  17031050500        North Center\n",
      "794  17031063200           Lake View\n",
      "795  17031070102        Lincoln Park\n",
      "796  17031071600            Old Town\n",
      "797  17031081500         River North\n",
      "798  17031140800         Albany Park\n",
      "799  17031160601         Irving Park\n",
      "800  17031842300         River North\n",
      "\n",
      "[801 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge neighborhood information onto each census tracts\n",
    "tracts = gpd.read_file(os.path.join('shapefiles', 'ti_2017_chi_tracts_simple.shp'))\n",
    "neighborhoods = gpd.read_file(os.path.join('shapefiles', 'ti_2012_chi_neighborhoods.shp')).to_crs(epsg = 4269)\n",
    "tandh = gpd.sjoin(\n",
    "    tracts.set_geometry(tracts.centroid),\n",
    "    neighborhoods,\n",
    "    how='left',\n",
    "    op='within')\n",
    "tandh = pd.DataFrame(tandh[['GEOID', 'PRI_NEIGH']])\n",
    "tandh['GEOID'] = tandh['GEOID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the files together, calculate the stores per 1K population, then output to shapefile\n",
    "tracts = gpd.read_file(os.path.join('shapefiles', 'ti_2017_chi_tracts_simple.shp'))\n",
    "tracts = tracts\\\n",
    "  .merge(counts, on='GEOID')\\\n",
    "  .merge(pop, on='GEOID')\\\n",
    "  .merge(tandh, on='GEOID')\n",
    "tracts['STORES_PER_1000'] = tracts['counts'] / tracts['POP'] * 1000\n",
    "tracts = tracts.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "tracts = gpd.GeoDataFrame(tracts)\n",
    "tracts.to_file(os.path.join('shapefiles', 'final_chi_tracts.shp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyterenv]",
   "language": "python",
   "name": "conda-env-jupyterenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
